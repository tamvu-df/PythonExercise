{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ex 4.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import tracemalloc\n",
    "def log_execution (func):\n",
    "    def wrapper(*args, **kwargs):\n",
    "        tracemalloc.start()\n",
    "        start  = time.time()\n",
    "        result = func(*args, **kwargs)\n",
    "        end = time.time()\n",
    "        current, peak = tracemalloc.get_traced_memory()\n",
    "        print(f\"Function: {func.__name__}, Time taken: {end - start} seconds\")\n",
    "        print(f\"Function: {func.__name__}, Memory used: {current} bytes, Peak Memory used: {peak} bytes\")\n",
    "        tracemalloc.stop()\n",
    "        return result\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "@log_execution\n",
    "def find_character (input_string, character):\n",
    "    for i in range(len(input_string)):\n",
    "        if input_string[i] == character:\n",
    "            return True\n",
    "        else:\n",
    "            return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function: find_character, Time taken: 0.0 seconds\n",
      "Function: find_character, Memory used: 72 bytes, Peak Memory used: 152 bytes\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_character(\"snfdskfnjsddsjqwieuqweqw\", 'a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ex 4.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def repeat(num_times):\n",
    "    def decorator(func):\n",
    "        def wrapper(*args, **kwargs):\n",
    "            result = []\n",
    "            for _ in range(num_times):\n",
    "                result.append(func(*args, **kwargs))\n",
    "\n",
    "            return result\n",
    "        return wrapper\n",
    "    return decorator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "@repeat(num_times=5)\n",
    "def find_character (input_string, character):\n",
    "    for i in range(len(input_string)):\n",
    "        if input_string[i] == character:\n",
    "            return True\n",
    "        else:\n",
    "            return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[False, False, False, False, False]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_character(\"ddfdfsdfsd\", \"a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ex 4.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Not using generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def read_file_no_yield():\n",
    "    with open(\"large_log_file.txt\", 'r') as file:\n",
    "        return file.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "@log_execution\n",
    "def search_error():\n",
    "    lines = read_file_no_yield()\n",
    "    for line in lines:\n",
    "        if \"ERROR\" in line:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function: search_error, Time taken: 17.682008266448975 seconds\n",
      "Function: search_error, Memory used: 149130 bytes, Peak Memory used: 954261774 bytes\n"
     ]
    }
   ],
   "source": [
    "search_error()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using a generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def read_file_with_yield():\n",
    "    with open(\"large_log_file.txt\") as file:\n",
    "        for line in file:\n",
    "            yield line.strip()\n",
    "@log_execution\n",
    "def search_error():\n",
    "    for line in read_file_with_yield():\n",
    "        if \"ERROR\" in line:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function: search_error, Time taken: 13.838605403900146 seconds\n",
      "Function: search_error, Memory used: 149030 bytes, Peak Memory used: 183207 bytes\n"
     ]
    }
   ],
   "source": [
    "search_error()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ex 4.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- MultiThreading: \tMultiple threads within the same process, sharing memory space.\n",
    "    - Best for: I/O-bound tasks, such as reading/writing files, network requests, and user interfaces where waiting for external resources is common.\n",
    "- Multiprocessing: Multiple processes with separate memory spaces, each running its own Python interpreter.\n",
    "    - Best for: CPU-bound tasks, such as mathematical calculations, image processing, and database operations where parallelism is beneficial.\n",
    "- Asynchronous Programming: Single-threaded event loop managing tasks via cooperative multitasking (tasks yield control).\n",
    "    - Best for: I/O-bound tasks like handling large numbers of network connections, APIs, real-time systems, and web scraping."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ex 4.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import aiofiles\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_directory(directory = \"files\"):\n",
    "    if os.path.exists(directory):\n",
    "    # If it exists, delete all files in the directory\n",
    "        for filename in os.listdir(directory):\n",
    "            file_path = os.path.join(directory, filename)\n",
    "            try:\n",
    "                if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "                    os.unlink(file_path)  # Remove the file\n",
    "                elif os.path.isdir(file_path):\n",
    "                    shutil.rmtree(file_path)  # Remove the sub-directory\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to delete {file_path}. Reason: {e}\")\n",
    "    else:\n",
    "        # If the directory does not exist, create it\n",
    "        os.makedirs(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_directory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Generate 1000 text files with random numbers of lines\n",
    "@log_execution\n",
    "def generate_files(directory = \"files\"):\n",
    "    for i in range(1000):\n",
    "        file_name = f\"{directory}/file_{i+1}.txt\"\n",
    "        num_lines = random.randint(1, 500)  # Random number of lines between 1 and 500\n",
    "        with open(file_name, 'w') as f:\n",
    "            for _ in range(num_lines):\n",
    "                f.write(\"This is a line of text.\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function: generate_files, Time taken: 1.4308009147644043 seconds\n",
      "Function: generate_files, Memory used: 148596 bytes, Peak Memory used: 190391 bytes\n"
     ]
    }
   ],
   "source": [
    "generate_files()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ex 4.6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Not using asynchronisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Create result.txt to store the number of lines for each file\n",
    "@log_execution\n",
    "def create_result_txt(path = \"result.txt\", directory = \"files\"):\n",
    "    with open(path, 'w') as result_file:\n",
    "        for i in range(1000):\n",
    "            file_name = f\"{directory}/file_{i+1}.txt\"\n",
    "            with open(file_name, 'r') as f:\n",
    "                lines =  f.readlines() \n",
    "                num_lines = len(lines)\n",
    "            result_file.write(f\"{file_name}: {num_lines} lines\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function: create_result_txt, Time taken: 4.20612907409668 seconds\n",
      "Function: create_result_txt, Memory used: 297286 bytes, Peak Memory used: 413516 bytes\n"
     ]
    }
   ],
   "source": [
    "create_result_txt()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using asynchronisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "@log_execution\n",
    "async def create_result_txt_with_async(path=\"result.txt\", directory=\"files\"):\n",
    "    async with aiofiles.open(path, 'w') as result_file:\n",
    "        for i in range(1000):\n",
    "            file_name = f\"{directory}/file_{i+1}.txt\"\n",
    "            async with aiofiles.open(file_name, 'r') as f:\n",
    "                lines = await f.readlines() \n",
    "                num_lines = len(lines) \n",
    "            await result_file.write(f\"{file_name}: {num_lines} lines\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function: create_result_txt_with_async, Time taken: 0.0 seconds\n"
     ]
    }
   ],
   "source": [
    "await create_result_txt_with_async()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "time_series_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
